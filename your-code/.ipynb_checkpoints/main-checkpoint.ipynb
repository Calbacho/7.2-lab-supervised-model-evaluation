{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning Model Evaluation Lab\n",
    "\n",
    "Complete the exercises below to solidify your knowledge and understanding of supervised learning model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "data = load_boston()\n",
    "\n",
    "X = pd.DataFrame(data[\"data\"], columns=data[\"feature_names\"])\n",
    "y = pd.DataFrame(data[\"target\"], columns=['MEDV'])\n",
    "\n",
    "data = pd.concat([X, y], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Split this data set into training (80%) and testing (20%) sets.\n",
    "\n",
    "The `MEDV` field represents the median value of owner-occupied homes (in $1000's) and is the target variable that we will want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  MEDV  \n",
       "0       15.3  396.90   4.98  24.0  \n",
       "1       17.8  396.90   9.14  21.6  \n",
       "2       17.8  392.83   4.03  34.7  \n",
       "3       18.7  394.63   2.94  33.4  \n",
       "4       18.7  396.90   5.33  36.2  \n",
       "..       ...     ...    ...   ...  \n",
       "501     21.0  391.99   9.67  22.4  \n",
       "502     21.0  396.90   9.08  20.6  \n",
       "503     21.0  396.90   5.64  23.9  \n",
       "504     21.0  393.45   6.48  22.0  \n",
       "505     21.0  396.90   7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('MEDV', axis=1)\n",
    "\n",
    "y = data.MEDV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404, 13), (102, 13), (404,), (102,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "X_train, X_test, y_train, y_test  = tts(X, y, train_size=0.8, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train a `LinearRegression` model on this data set and generate predictions on both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression as LinReg\n",
    "linreg=LinReg()\n",
    "linreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([10.96952405, 19.41196567, 23.06419602, 12.1470648 , 18.3738116 ,\n",
       "        25.24677946, 20.77024774, 23.90932632,  7.81713319, 19.60988098,\n",
       "        21.8202963 , 27.59615864, 32.67986504, 15.12308446, 35.3964561 ,\n",
       "        12.99688651, 20.728181  , 28.30223542, 15.61724836, 24.45143096,\n",
       "         4.61794591, 23.76681932, 25.56178249, 22.98928526, 24.5213025 ,\n",
       "        34.06407919, 19.71166707, 39.11233072, 14.62515846, 24.81139885,\n",
       "        18.02332883, 20.85836445,  9.57577261, 20.87246835, 22.28583096,\n",
       "        31.79327155, 31.04748307, 15.70611763, 17.01382935, 28.23332703,\n",
       "        24.27661276, 16.88670215,  6.90720745, 26.75808901, 22.586493  ,\n",
       "        17.53664716, 13.77197016, 41.04840929, 16.44690754, 18.23531669,\n",
       "        25.37038646, 23.64581399, 22.05322581, 20.83620499, 16.93508273,\n",
       "        22.797579  , 29.13333934,  7.69310515, 24.60571452, 17.2358028 ,\n",
       "        21.10846551, 25.15150324, 27.33394823, 21.30494963, 41.5811902 ,\n",
       "        19.19666651, 15.37955448, 19.33545877, 17.04687638, 22.96801532,\n",
       "        23.11094953, 33.6977586 , 22.77436405, 20.28968381, 25.35517813,\n",
       "        31.02479125, 33.05103792, 28.44712333,  8.50926331,  5.61220643,\n",
       "        12.81228164, 19.81854491, 34.8603548 , 33.47481463, 15.81288676,\n",
       "         4.16863764, 32.81131556, 21.22307142, 18.97752706, 26.36174269,\n",
       "        18.38053781, 17.80316891, 11.8730344 , 31.84801205, 24.45344478,\n",
       "        20.0222241 , 19.5225374 , 11.8723419 , 28.90289906, 19.7133604 ,\n",
       "        32.47093634, 33.20696505, 24.79405395, 21.25197228, 25.03045081,\n",
       "        43.36995367, 29.54151469, 33.75302939, 26.27516427, 27.04791799,\n",
       "        15.1908027 , 31.34177077, 20.85218327, 31.05070715, 28.74449991,\n",
       "        21.16535503, 23.06717742, 12.48881717, 36.48751917, 37.24291141,\n",
       "        33.23617345,  5.30863493, 20.82773333, 22.16769067, 35.62579793,\n",
       "        17.10890633, 22.76667   , 19.50567599, 26.36980524, 16.03780391,\n",
       "        20.63186041, 27.04508116, 31.39596353, 31.12597743, 22.78355908,\n",
       "        39.11521781, 28.28378993, 30.53090392, 28.89518723, 21.08389783,\n",
       "        29.04801464, 16.151087  , 22.08243372, 24.61505524, 18.95878457,\n",
       "         2.06366066, 20.51120467, 26.85927261, 23.0775764 , 18.40141847,\n",
       "        22.70378324, 15.95162657, 31.54559763, 27.82356386, 34.19210038,\n",
       "        20.70876151, 15.1538496 , 19.55740929,  8.31853813, 13.62525632,\n",
       "        26.48611752, 16.52769982,  4.13593772, 24.73356662, 12.21856959,\n",
       "        28.24704463, 33.60549853, 36.84177072, 24.28136146, 20.7199677 ,\n",
       "        30.79885576, 36.93823489, 19.92152434, 19.59433404, 28.76197718,\n",
       "        13.28347615, 13.41116334, 10.89910148, 19.07573086, 22.65911351,\n",
       "        30.27080271, 29.77482371, 17.89252221, 29.83838757, 14.41987694,\n",
       "        13.24056207, 33.87859379, 19.6406762 , 14.54072369, 23.66498192,\n",
       "        22.41851151, 19.63248447, 24.660086  , 35.00833944,  4.12171868,\n",
       "        20.79593953, 33.240402  , 18.04778742, 22.6208596 , 22.39592759,\n",
       "        21.4012853 , 11.74782838, 38.18786922, 25.76751814, 24.80115706,\n",
       "        16.36524419, 31.98045427, 36.35420843, 39.11016375, 20.33864814,\n",
       "        22.16464728, 16.34276966, 39.35137104,  6.74954317, 21.35789894,\n",
       "        15.53370378, 26.91527204,  8.80382559, 20.93301971, -0.20588155,\n",
       "        17.21501492, 16.17150935,  8.48374754, 23.08202496, 17.23085262,\n",
       "        29.42673011, 44.36436789, 28.09470335, 23.75911874, 36.75959172,\n",
       "         8.71594791, 25.90885934, 20.83832124, 23.68119542, 19.85753143,\n",
       "        22.2992237 , 14.72942336, 18.4266911 , 22.45346464, 23.75648384,\n",
       "        28.82492146, 23.58310886, 27.30142666, 18.06532614, 13.16799771,\n",
       "        31.66795775, 28.77291955, 12.60179253, 17.38668341, 24.05174693,\n",
       "        40.7163898 , 23.0214736 , 12.83596226, 28.55024128, 36.850343  ,\n",
       "        23.26391794, 25.14113573, 38.36624745, 18.21318365, 25.69614391,\n",
       "        15.22833068, 24.14345412, 36.27095489, 31.03140871, 24.82017075,\n",
       "        17.7834844 , 17.99307546,  8.61827851, 41.51965821, 19.63259696,\n",
       "        30.16241039, 19.69581658, 14.59963591, 20.29467675, 24.22053288,\n",
       "        34.79282666, 26.51552807, 41.665796  , 12.32829593, 14.32092274,\n",
       "        23.69090327, 18.01762114, 19.72399411, 29.13009315, 11.10216617,\n",
       "        24.11213143, 18.54668994, 23.69765843, 30.11853879, 19.34756033,\n",
       "        12.52355093, 33.74737806, 16.90295464, 17.83165159, 19.34064029,\n",
       "        26.74379491, 35.24575625, 12.92253178, 26.69073573, 19.19640769,\n",
       "        30.29549933, 17.83878909, 22.92058129, 29.13254708, 20.02093559,\n",
       "        25.18893157, 20.95650827, 20.57624549, 32.93168351, 20.43565472,\n",
       "        25.41798459, 28.14952635, 37.59066882, 25.0548289 , 28.61534646,\n",
       "        17.97695227, 30.78085325, 23.57491321, 34.56676284, 18.52592551,\n",
       "        23.86972656, 13.82862001, 25.18152388, 17.67219765, 12.63704156,\n",
       "        17.03927502, 14.2510159 , 28.56862619, 22.99037971, 13.42262376,\n",
       "        17.40965124, 34.44268371, 12.93938984, 14.62427657, 27.50209814,\n",
       "        21.28772373, 21.8475453 , 27.75030943, 16.84106111, 35.70395065,\n",
       "        23.19717187, 19.70894368, 20.39856551, 31.03155183,  5.16165827,\n",
       "        36.26386827, 38.27409562, 21.44507004, 21.53203698, 13.25546637,\n",
       "        35.43733953, 19.75468373, 21.59325014, 27.28654912, 14.70336355,\n",
       "        20.10948908, 20.98738625, 20.42268561, 26.20840113, 11.28815662,\n",
       "        34.57059129, 22.65270668, 22.68814063, 33.20155069, 26.77878535,\n",
       "        21.55230365,  8.80963918, 28.40878163, 25.10012639, 25.47646583,\n",
       "        17.70215249, 25.63601841, 18.61140436, 32.77937269, 35.77461311,\n",
       "        18.3180684 , 30.14080347,  7.72488159, 26.25987699, 10.52826879,\n",
       "        27.30604251, 44.10078731, 28.92351314, 14.7836951 , 20.79445301,\n",
       "        17.96782515, 19.333174  , 33.02714571, 25.71055958, 25.89232968,\n",
       "        17.07165041, 21.95432205, 11.3511532 , 13.27742402, 22.66485295,\n",
       "        22.52252947, 12.30424735, 32.08396429, 22.11175771, 17.24071878,\n",
       "        22.00480027, 26.7237425 , 12.97674212, 19.14279551]),\n",
       " array([28.99672362, 36.02556534, 14.81694405, 25.03197915, 18.76987992,\n",
       "        23.25442929, 17.66253818, 14.34119   , 23.01320703, 20.63245597,\n",
       "        24.90850512, 18.63883645, -6.08842184, 21.75834668, 19.23922576,\n",
       "        26.19319733, 20.64773313,  5.79472718, 40.50033966, 17.61289074,\n",
       "        27.24909479, 30.06625441, 11.34179277, 24.16077616, 17.86058499,\n",
       "        15.83609765, 22.78148106, 14.57704449, 22.43626052, 19.19631835,\n",
       "        22.43383455, 25.21979081, 25.93909562, 17.70162434, 16.76911711,\n",
       "        16.95125411, 31.23340153, 20.13246729, 23.76579011, 24.6322925 ,\n",
       "        13.94204955, 32.25576301, 42.67251161, 17.32745046, 27.27618614,\n",
       "        16.99310991, 14.07009109, 25.90341861, 20.29485982, 29.95339638,\n",
       "        21.28860173, 34.34451856, 16.04739105, 26.22562412, 39.53939798,\n",
       "        22.57950697, 18.84531367, 32.72531661, 25.0673037 , 12.88628956,\n",
       "        22.68221908, 30.48287757, 31.52626806, 15.90148607, 20.22094826,\n",
       "        16.71089812, 20.52384893, 25.96356264, 30.61607978, 11.59783023,\n",
       "        20.51232627, 27.48111878, 11.01962332, 15.68096344, 23.79316251,\n",
       "         6.19929359, 21.6039073 , 41.41377225, 18.76548695,  8.87931901,\n",
       "        20.83076916, 13.25620627, 20.73963699,  9.36482222, 23.22444271,\n",
       "        31.9155003 , 19.10228271, 25.51579303, 29.04256769, 20.14358566,\n",
       "        25.5859787 ,  5.70159447, 20.09474756, 14.95069156, 12.50395648,\n",
       "        20.72635294, 24.73957161, -0.164237  , 13.68486682, 16.18359697,\n",
       "        22.27621999, 24.47902364]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred = linreg.predict(X_train)\n",
    "y_test_pred = linreg.predict(X_test)\n",
    "\n",
    "y_train_pred, y_test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calculate and print R-squared for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7508856358979673, 0.6687594935356332)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score as r2\n",
    "\n",
    "r2(y_train, y_train_pred), r2(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate and print mean squared error for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21.641412753226312, 24.291119474973428)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "mse(y_train, y_train_pred), mse(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Calculate and print mean absolute error for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.3147716267832292, 3.1890919658878354)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error as mae  # estos alias tmb son cosa mia\n",
    "\n",
    "mae(y_train, y_train_pred), mae(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "data = load_iris()\n",
    "\n",
    "X = pd.DataFrame(data[\"data\"], columns=data[\"feature_names\"])\n",
    "y = pd.DataFrame(data[\"target\"], columns=[\"class\"])\n",
    "\n",
    "data = pd.concat([X, y], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Split this data set into training (80%) and testing (20%) sets.\n",
    "\n",
    "The `class` field represents the type of flower and is the target variable that we will want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('class', axis=1)\n",
    "\n",
    "y = data['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120, 4), (30, 4), (120,), (30,))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "X_train, X_test, y_train, y_test  = tts(X, y, train_size=0.8, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train a `LogisticRegression` model on this data set and generate predictions on both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg=LogisticRegression(max_iter = 4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=4000)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0, 0, 1, 2, 2, 1, 2, 1, 2,\n",
       "        1, 0, 2, 1, 0, 0, 0, 1, 2, 0, 0, 0, 1, 0, 1, 2, 0, 1, 2, 0, 2, 2,\n",
       "        1, 1, 2, 1, 0, 1, 2, 0, 0, 1, 2, 0, 2, 0, 0, 2, 1, 2, 2, 2, 2, 1,\n",
       "        0, 0, 2, 2, 0, 0, 0, 1, 2, 0, 2, 2, 0, 1, 1, 2, 1, 2, 0, 2, 1, 2,\n",
       "        1, 1, 1, 0, 1, 1, 0, 1, 2, 2, 0, 1, 2, 2, 0, 2, 0, 1, 2, 2, 1, 2,\n",
       "        1, 1, 2, 2, 0, 1, 2, 0, 1, 2]),\n",
       " array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
       "        0, 2, 2, 2, 2, 2, 0, 0]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred = logreg.predict(X_train)\n",
    "y_test_pred = logreg.predict(X_test)\n",
    "\n",
    "y_train_pred, y_test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Calculate and print the accuracy score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.975, 1.0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " accuracy_score(y_train, y_train_pred),  accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Calculate and print the balanced accuracy score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.975609756097561, 1.0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "balanced_accuracy_score(y_train, y_train_pred),  balanced_accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Calculate and print the precision score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9761904761904763, 1.0)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score as prec\n",
    "\n",
    "prec(y_train, y_train_pred, average='macro'),  prec(y_test, y_test_pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Calculate and print the recall score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.975609756097561, 1.0)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score as rec\n",
    "\n",
    "rec(y_train, y_train_pred, average='macro'),  rec(y_test, y_test_pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Calculate and print the F1 score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.        , 0.96202532, 0.96296296]), array([1., 1., 1.]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score as f1\n",
    "\n",
    "f1(y_train, y_train_pred, average=None),  f1(y_test, y_test_pred, average=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Generate confusion matrices for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[40,  0,  0],\n",
       "        [ 0, 38,  3],\n",
       "        [ 0,  0, 39]], dtype=int64),\n",
       " array([[10,  0,  0],\n",
       "        [ 0,  9,  0],\n",
       "        [ 0,  0, 11]], dtype=int64))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix as cm\n",
    "\n",
    "cm(y_train, y_train_pred),  cm(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: For each of the data sets in this lab, try training with some of the other models you have learned about, recalculate the evaluation metrics, and compare to determine which models perform best on each data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
